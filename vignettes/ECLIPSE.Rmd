---
title: "ECLIPSE Quick Start"
author: 
- name: "Jared Andrews"
  email: jared.andrews07@gmail.com
  affiliation: St. Jude Children's Research Hospital, Memphis, TN
date: "`r BiocStyle::doc_date()`"
output: 
  BiocStyle::html_document:
    code_folding: show
    toc: true
    toc_depth: 3
    toc_float: true
vignette: >
  %\VignetteIndexEntry{ECLIPSE Quick Start}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include=FALSE}
library(BiocStyle)
knitr::opts_chunk$set(echo = TRUE, fig.align = "center", message = FALSE, warning = FALSE)
```

# Introduction

**ECLIPSE** (**E**nhancer **C**alling and **L**inking with **I**ntegrated **P**rofiling and **S**tructure **E**valuation) provides a performant 
implementation of the [rank ordering of super enhancers (ROSE)](http://younglab.wi.mit.edu/super_enhancer_code.html) method for identifying super enhancers.
It provides options to increase the robustness of ROSE via signal transformations prior to thresholding and additional thresholding approaches.
It also increases flexibility by exposing parameters hidden in the original implementation.
ECLIPSE additionally contains novel functionality to identify sub-structural changes within enhancer regions between groups via sliding window and binning approaches.
It also contains visualization functions to generate high-quality plots of specific loci alongside arbitrary user-provided data.

## Installation

**ECLIPSE** is currently available on Github and can be installed as follows:

```{r, eval = FALSE}
if (!requireNamespace("devtools", quietly = TRUE))
    install.packages("devtools")

devtools::install_github("j-andrews7/ECLIPSE")
```

## Usage

Given paths to a BAM file and a BED file of peaks, ROSE can be run with the `run_rose` function.
Optionally, a control BAM file for input or IgG from the same sample can be provided.

Alternatively, `bamFile` objects for the treatment and control signal and a `GRanges` object for the peaks can be provided.

The output is a `GRanges` object containing all putative enhancers with their super enhancer designation in the `super` metadata column.

Below is an example of running ROSE on a BAM file of H3K27ac MINT ChIP-seq, an [input control](https://www.encodeproject.org/experiments/ENCSR056PPJ/) BAM file, and a BED file of peaks from [this ENCODE experiment of human naive B cells](https://www.encodeproject.org/experiments/ENCSR660EVU/).

```{r, eval = FALSE}
library(ECLIPSE)
# We'll use the BiocFileCache package to download and cache the files, which will take a few minutes the first time they're used.
library(BiocFileCache)

# For annotation
library(TxDb.Hsapiens.UCSC.hg38.knownGene)
library(org.Hs.eg.db)

txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene

# Limit to canonical chromosomes, out of bound warnings will abound if not done
txdb <- keepStandardChromosomes(txdb, pruning.mode = "coarse")
org.db <- org.Hs.eg.db

bfc <- BiocFileCache(ask = FALSE)
treat_url <- "https://www.encodeproject.org/files/ENCFF993DJI/@@download/ENCFF993DJI.bam"
treat_path <- bfcrpath(bfc, treat_url)

treat_bw_url <- "https://www.encodeproject.org/files/ENCFF901BFR/@@download/ENCFF901BFR.bigWig"
treat_bw_path <- bfcrpath(bfc, treat_bw_url)

control_url <- "https://www.encodeproject.org/files/ENCFF821MAI/@@download/ENCFF821MAI.bam"
control_path <- bfcrpath(bfc, control_url)

peaks_url <- "https://www.encodeproject.org/files/ENCFF590DFY/@@download/ENCFF590DFY.bed.gz"
peaks_path <- bfcrpath(bfc, peaks_url)

treat_bam <- BamFile(treat_path)
control_bam <- BamFile(control_path)
peaks <- readBed(peaks_path)

naiveB1_enhancers <- run_rose(treatment = treat_bam, control = control_bam, peaks = peaks,
                              txdb = txdb, org.db = org.db, stitch.distance = 12500, tss.exclusion.distance = 2500,
                              max.unique.gene.tss.overlap = 2,
                              drop.no.signal = TRUE)

naiveB1_enhancers_width_normalized <- run_rose(treatment = treat_bam, control = control_bam, peaks = peaks,
                              txdb = txdb, org.db = org.db, stitch.distance = 12500, tss.exclusion.distance = 2500,
                              max.unique.gene.tss.overlap = 2,
                              drop.no.signal = TRUE,
                              normalize.by.width = TRUE)

naiveB1_enhancers
```

### Other Input Types

Though the example above uses BAM files, `run_rose` can also accept BigWig or bedGraph signal files, though doing so alters the coverage calculation. See `?run_rose` for more information.

### Visualization

Can't be a super enhancer package without the classic swoosh plot.

```{r}
plot_enhancer_curve(naiveB1_enhancers, factor_label = "H3K27ac")
```


## Comparison to Original ROSE Implementation

With default parameters, `run_rose` is an attempt to closely match the results from the original ROSE implementation.

For comparison's sake, here is the enhancer ranking curve from the original ROSE implementation for [H3K27ac Mint-ChIP-seq from
naive B cells](https://www.encodeproject.org/experiments/ENCSR660EVU/) as provided by ENCODE:

```{r, fig.cap="Enhancer rank plot output by original ROSE implementation.", echo=FALSE}
knitr::include_graphics("ENCFF590DFY_Plot_points.png")
```

These results are using no TSS exclusion to compare the underlying classification approach as closely as possible.

Notably, the number of super-enhancers identified are not a perfect match due to very slight differences in the coverage calculations.
However, all super-enhancers identified in the original implementation are also called by ECLIPSE.
Determination of the root cause of the minor discrepancy is ongoing.

### Known Methodological Differences between ECLIPSE and ROSE

 - ROSE performs read extension after pulling all reads that overlap a region, whereas ECLIPSE extends all reads and then pulls those that overlap. This is much faster, but likely results in very minor coverage calculation differences.
 
## Important Observations of ROSE

We have closely examined and tested the ROSE source code and have made the following observations:

 1. ROSE does not use region size scaling for final signal ranking in a meaningful way. The signals in ROSE are derived as follows:
   - All reads overlapping a given region are pulled.
   - These reads are extended by 200 bp.
   - The coverage for each base in the region is counted (via samtools view, which is very slow when done on each individual region). 
     - There are alternative implementations floating around Github that use a tool called bamliquidator that is much faster, but it's also difficult to install and poorly supported.
   - The coverage for the region is summed and divided by the region width to generate a density factor.
   - The density factor is then divided by the MMR factor (mapped reads/1000000) to generate a library size-normalized signal factor.
   - This factor is saved for each stitched region into the "mapped GFF" files.
   - The "signal" is then calculated from the "mapped GFF" files for the stitched regions by multiplying the library size-normalized factor by the width of the region. Ultimately, this just results in the library size-normalized sum of coverage for a region, independent of its size (ADD EXAMPLE TO DEMONSTRATE THIS.)
     - This biases ROSE towards large regions, potentially ignoring smaller regions that have a higher signal density that may still have an outsized regulatory impact. This is worth exploring further.
   - ECLIPSE provides an option (`normalize.by.width`) to scale the final signal by the total constituent peak width for each region.
 2. ROSE has a bug in the unstitching process whereby it rarely does not unstitch regions that clearly span TSSes from 3 or more unique genes.
   - What exactly the bug is remains unclear, but it may be related to how ROSE is performing overlaps.
   - ECLIPSE does not have this issue, which alters the final number of regions returned (and thus SEs called) to a minor degree.
 3. Outliers have an outsized impact on the signal ranking and final classifications in ROSE.
   - To elaborate, if you remove the top 5 or 10 regions by signal, the ranking of the remaining regions changes dramatically and the threshold for super-enhancer classification is much different. This results in fickle classifications whereby you can easily get 100s more/less SEs from sample to sample of the exact same tissue or cell type just depending on how dramatic the outliers are.
   - We *highly* recommend using the transformation capabilities included in ECLIPSE to monotonically transform the signal prior to ranking, which will dramatically reduce the impact of outliers on the final classification while maintaining the same rank. See the `transformation`, `thresh.method`, `first.threshold`, and `arbitrary.threshold` parameters in `?run_rose` for options and additional information.
   
This list is incomplete and will be updated as we continue to explore the differences between ECLIPSE and ROSE.

## Running with TSS Exclusion

ROSE is frequently ran with TSS exclusion to remove peaks fully contained within a window (usually +/- 2.5kb) around each TSS.

What is less well documented in the original ROSE implementation is that this also invokes an unstitching process of regions that overlap TSSes (+/- 50 bp) from 3 or more unique genes, whereby a stitched region is then split back into its original constituent elements. 

The original implementation provides no way to alter or disable this behavior, but ECLIPSE does.

```{r}
# With TSS exclusion and unstitching, a la the original ROSE implementation
res_tss_exl <- run_rose(treatment = treat_path, 
                        control = control_path, 
                        peaks = peaks_path,
                        txdb = txdb,
                        tss.exclusion.distance = 2500,
                        max.unique.gene.tss.overlap = 2)

# With TSS exclusion but no unstitching
res_tss_exl_no_unstitch <- run_rose(treatment = treat_path, 
                                    control = control_path, 
                                    peaks = peaks_path,
                                    txdb = txdb,
                                    tss.exclusion.distance = 2500,
                                    max.unique.gene.tss.overlap = NULL)
```

We can then see how these differ in the number of SEs identified.

With TSS exclusion and unstitching, as is commonly done with the original implementation for H3K27ac data:

```{r}
plot_enhancer_curve(res_tss_exl, factor_label = "H3K27ac")
```

With TSS exclusion but no unstitching:

```{r}
plot_enhancer_curve(res_tss_exl_no_unstitch, factor_label = "H3K27ac")
```

These settings have dramatic impacts on the final number of regions returned and the number (and size) of SEs identified.

```{r}
message("Number of regions returned with TSS exclusion and unstitching: ", length(res_tss_exl))
message("Number of regions returned with TSS exclusion and no unstitching: ", length(res_tss_exl_no_unstitch))

message("Number of SEs identified with TSS exclusion and unstitching: ", length(res_tss_exl[res_tss_exl$super]))
message("Number of SEs identified with TSS exclusion and no unstitching: ", length(res_tss_exl_no_unstitch[res_tss_exl_no_unstitch$super]))

message("Average width of SEs with TSS exclusion and unstitching: ", mean(width(res_tss_exl[res_tss_exl$super])))
message("Average width of SEs with TSS exclusion and no unstitching: ", mean(width(res_tss_exl_no_unstitch[res_tss_exl_no_unstitch$super])))
```

Given the lack of documentation or discussion on this behavior in the original implementation or papers, it is unclear how this should be handled in practice.

### Other Previously Hidden Parameters

**ECLIPSE** also allows things like read extension length to be adjusted, which ROSE sets at 200 with no convenient way to adjust.

Though this is a reasonable estimate for most ChIP-seq data, we can also determine the fragment length from the data as specified by [csaw](https://bioconductor.org/books/3.20/csawBook/counting-reads-into-windows.html#sec:ccf).

```{r}
# Removing duplicates for this is often necessary as there tends to be an artifactual peak at a distance equal to the read length.
dedup.param <- readParam(minq=20, dedup=TRUE)
x <- correlateReads(treat_path, max.dist = 500, param = dedup.param)
plot(0:500, x, type="l", ylab="CCF", xlab="Delay (bp)")
```

200 bp is a reasonable estimate, but we could also use the peak of the cross-correlation function as the 
fragment length to provide to the `read.ext` parameter in `run_rose`.

```{r}
frag.len <- maximizeCcf(x)
```


## Using BigWig or bedGraph Inputs

At times, it may be more convenient to use BigWig or bedGraph files for signal input. 
These can be imported as GRanges objects and passed as inputs to `run_rose`.

ECLIPSE handles these slightly different than BAM files, for which it uses the total number of reads as an additional normalization step, as that's what ROSE does.
ECLIPSE presumes that the signal is already normalized for library size and does not perform this step.

In some cases, the input or IgG control signal has already been incorporated (subtracted out, used to calculate a BigWig of foldchanges, etc) as appropriate and thus will not be provided. 

This is one such case, as this BigWig file is the foldchange of H3K27ac signal in naive B cells over input.

As such, it makes sense to set `floor = 0` for the "signal" calculation as much of the artifact noise should have been removed.

```{r}
library(rtracklayer)

naiveB1_bw <- rtracklayer::import(treat_bw_path)

naiveB1_enhancers_bigwig <- run_rose(treatment = naiveB1_bw, peaks = peaks,
                              txdb = txdb, org.db = org.db, stitch.distance = 12500, tss.exclusion.distance = 2500,
                              max.unique.gene.tss.overlap = 2, floor = 0, normalize.by.width = TRUE)
```

## Exploring Transformations & Thresholding Methods

As mentioned above, ROSE is highly sensitive to outliers in the signal, which can dramatically alter the final classification of regions.
ECLIPSE provides a parameter for applying a transformation function to all regions prior to ranking to reduce the impact of outliers on the final classification.

However, it is unclear which transformation(s) are most appropriate for this task.
These transformations may also change the shape of the curve, which may necessitate a change in the thresholding method used.

### Transformations

As it stands, the original ROSE implementation uses an arbitrary thresholding approach.
It'd be nice to use a more statistically rigorous approach based on the distribution of the (potentially width-normalized) signal for each region.

It'd be convenient if we could get a relatively normal distribution of signal values for each region, which would allow us to use a Z-score or similar approach to thresholding.

As such, let's test a few transformations, make some histograms/qqplots, and see what looks best.
We will also do this for width-normalized signal to see how that looks.

```{r}
logistic_transform_scaled_robust <- function(x) {
  center <- median(x, na.rm = TRUE)
  spread <- IQR(x, na.rm = TRUE) # interquartile range
  if (spread == 0) spread <- 1   # fallback if IQR=0
  
  1 / (1 + exp(-(x - center) / spread))
}

probit_transform_scaled_robust <- function(x) {
  center <- median(x, na.rm = TRUE)
  spread <- IQR(x, na.rm = TRUE)
  if (spread == 0) spread <- 1
  
  pnorm((x - center) / spread)
}


# --------------------------------------------------
# 2) Winsorized Min–Max Scaling
# --------------------------------------------------
#   - Caps extreme values at chosen quantiles
#   - Then applies linear min–max scaling
#   - Maps data into [0, 1]

winsorized_minmax_scale <- function(x, upper_quantile = 0.999, lower_quantile = 0.01) {
  # 1) Identify cutoffs
  q_high <- quantile(x, probs = upper_quantile)
  q_low  <- quantile(x, probs = lower_quantile)
  
  # 2) Winsorize
  x_winsor <- pmax(pmin(x, q_high), q_low)
  
  # 3) Min–Max scaling
  x_min <- min(x_winsor)
  x_max <- max(x_winsor)
  
  (x_winsor - x_min) / (x_max - x_min)
}


# --------------------------------------------------
# 3) Rank-Inverse Normal Transform (RINT)
# --------------------------------------------------
#   - Rank the data -> convert rank to percentile -> map via inverse normal
#   - Often used to create data with near-Gaussian distribution

rint_transform <- function(x) {
  # 1) Get rank-based percentile
  r <- rank(x, ties.method = "average", na.last = "keep")
  n <- sum(!is.na(x))
  # Convert rank to a fraction in (0,1). 
  # Add a small offset to avoid exactly 0 or 1.
  p <- (r - 0.5) / n
  
  # 2) Map percentiles via inverse normal (qnorm)
  qnorm(p)
}


# --------------------------------------------------
# 4) Combination: Log + Min–Max
# --------------------------------------------------
#   - First apply a log-like transform (log or log1p) 
#   - Then map results into [0,1] with min–max scaling
#   - Uses pseudocount to avoid 0/negative values

log_minmax_transform <- function(x) {
  # 1) Log transform
  x_log <- log1p(x) # or simply log(x_shifted)
  
  # 2) Min–Max scale
  x_min <- min(x_log)
  x_max <- max(x_log)
  (x_log - x_min) / (x_max - x_min)
}


# --------------------------------------------------
# 5) Combination: asinh + Min–Max
# --------------------------------------------------
#   - arcsinh is a 'soft log' that can handle negative values
#   - Then do min–max scaling
#   - Very useful when data can be negative and large positive

asinh_minmax_transform <- function(x, scale_param = 1) {
  # 1) 'soft log' transform
  x_asinh <- asinh(scale_param * x)
  
  # 2) Min–Max scale
  x_min <- min(x_asinh)
  x_max <- max(x_asinh)
  
  (x_asinh - x_min) / (x_max - x_min)
}


# --------------------------------------------------
# Other basic transforms
# --------------------------------------------------

## Power transform: x^alpha
power_transform <- function(x, alpha = 0.2) {
  x^alpha
}

# Normalize to between [0, 1] and then cube to create more separation at high values 
scale_cube_transform <- function(x) { 
    x <- x
    mmax <- max(x)
    mmin <- min(x)
    x <- (x-mmin)/pmax(mmax-mmin, 1e-8)
    x <- x^3
    x
}

# Cumulative proportion of signal for each element
cumal_prop_transform <- function(x) {
    x <- x/sum(x)
    x <- cumsum(x)
    x <- 1 - x # Reverse so that the highest values are at the top
    x
}

# Cumulative proportion of signal for each element
cumal_prop_log2_transform <- function(x) {
    x <- log2(x)
    x <- x/sum(x)
    x <- cumsum(x)
    x <- 1 - x # Reverse so that the highest values are at the top
    x
}

## sqrt transform
sqrt_transform <- function(x) {
  sqrt(x)
}

## cuberoot transform
cuberoot_transform <- function(x) {
  x^(1/3)
}

## Box-Cox: (x^lambda - 1) / lambda, with log fallback
boxcox_transform <- function(x, lambda = 0.2) {
  if (lambda == 0) {
    log(x)
  } else {
    (x^lambda - 1) / lambda
  }
}

## Robust z-score transform: (x - median) / MAD
robust_z_transform <- function(x) {
  (x - median(x)) / mad(x)
}

## And with log2 transformation first
robust_log2_z_transform <- function(x) {
  (log2(x) - median(log2(x))) / mad(log2(x))
}

## log1p transform: log(1 + x)
log1p_transform <- function(x) {
  log1p(x)
}

## arcsinh transform
asinh_transform <- function(x) {
  asinh(x)
}

## arcsinh with scaling
asinh_transform_scaled <- function(x) {
    scale <- IQR(x, na.rm = TRUE) # interquartile range
    asinh(scale * x) / scale
}

## Classic min–max (no winsorizing)
minmax_scale <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

## Logistic transform (simple)
logistic_transform <- function(x) {
  1 / (1 + exp(-x))
}

# Winsorization
winsorize_transform <- function(x, upper_quantile = 0.999, lower_quantile = 0.01) {
  q_high <- quantile(x, probs = upper_quantile)
  q_low  <- quantile(x, probs = lower_quantile)
  
  pmax(pmin(x, q_high), q_low)
}

# Modified winsorization where rank of winsorized values are maintained by adding rank of winsorized values * a pseudocount
# Only applied to upper quantile.
winsorize_maintain_rank_transform <- function(x,
                                  upper_quantile = 0.999,
                                  pseudocount = 0.1) {
  # 1) Find the capping threshold
  cap_value <- quantile(x, probs = upper_quantile)
  message("Winsorizing at value: ", cap_value)
  
  # 2) Identify which x values exceed that threshold
  idx_above <- which(x > cap_value)
  
  if (length(idx_above) > 0) {

      # 3) Extract the subset of x that are above the threshold
      x_above <- x[idx_above]
      
      # 4) Determine the relative rank among these "above" values
      #    We'll assign a strictly increasing offset based on rank order.
      #    Order them from smallest to largest, then assign rank 1, 2, 3, ...
      order_above <- order(x_above)       # returns indices of x_above in ascending order
      ranks       <- seq_along(x_above)   # 1 to number of capped points

      new_values <- numeric(length(x_above))
      
      # 5) For each capped value, set it to cap_value + (pseudocount * rank)
      #    This ensures no ties among capped points and preserves their internal order.
      for (i in seq_along(order_above)) {
        # 'order_above[i]' is the index in 'x_above' of the i-th smallest capped value
        idx_in_x_above <- order_above[i]  # e.g. i-th smallest gets rank i
        new_values[idx_in_x_above] <- cap_value + (pseudocount * ranks[i])
      }
      
      # 6) Put these new values back into 'x' at the original positions of the capped points
      x_wins <- x
      x[idx_above] <- new_values
    }
  x
}

```

Now for each transformation function, we'll apply it to the signal to the signal column and plot the histograms, qqplots, and rank plot.

```{r}
sig <- naiveB1_enhancers$rankby_signal
sig_width_norm <- naiveB1_enhancers_width_normalized$rankby_signal

# Named list of transformations, underscore delimiter
transformations <- list(
  logistic_transform_scaled_robust = logistic_transform_scaled_robust,
  probit_transform_scaled_robust = probit_transform_scaled_robust,
  winsorized_minmax_scale = winsorized_minmax_scale,
  rint_transform = rint_transform,
  log_minmax_transform = log_minmax_transform,
  asinh_minmax_transform = asinh_minmax_transform,
  power_transform = power_transform,
  scale_cube_transform = scale_cube_transform,
  cumal_prop_transform = cumal_prop_transform,
  cumal_prop_log2_transform = cumal_prop_log2_transform,
  sqrt_transform = sqrt_transform,
  cuberoot_transform = cuberoot_transform,
  boxcox_transform = boxcox_transform,
  robust_z_transform = robust_z_transform,
  #robust_log2_z_transform = robust_log2_z_transform,
  log1p_transform = log1p_transform,
  asinh_transform = asinh_transform,
  asinh_transform_scaled = asinh_transform_scaled,
  minmax_scale = minmax_scale,
  logistic_transform = logistic_transform,
  winsorize_transform = winsorize_transform,
  winsorize_maintain_rank_transform = winsorize_maintain_rank_transform
)

transformed_SEs <- lapply(transformations, function(f) f(sig))

# Plot histograms and qqplots in PDF with new page for each transformation, both plots on one page
pdf("transformed_signal_distributions.NaiveB1.pdf", width = 15, height = 6)
par(mfrow = c(1, 3))
for (i in seq_along(transformed_sigs)) {
  hist(transformed_SEs[[i]]$rankyby_signal, main = names(transformations)[[i]], xlab = "Transformed Signal", breaks = 50)
  qqnorm(transformed_sigs[[i]]$rankyby_signal, main = names(transformations)[[i]])
}
dev.off()

transformed_sigs_width_norm <- lapply(transformations, function(f) f(sig_width_norm))

# Plot histograms and qqplots in PDF with new page for each transformation, both plots on one page
pdf("transformed_signal_distributions.NaiveB1.width_norm.pdf", width = 15, height = 6)
par(mfrow = c(1, 3))
for (i in seq_along(transformed_sigs_width_norm)) {
  hist(transformed_sigs_width_norm[[i]], main = names(transformations)[[i]], xlab = "Transformed Signal", breaks = 50)
  qqnorm(transformed_sigs_width_norm[[i]], main = names(transformations)[[i]])
}
dev.off()
```

## Differential Sub-Structural Analysis

ECLIPSE also provides functionality to identify sub-structural changes within super enhancer regions between groups via differential analysis of small bins.

For this example, we'll compare naive B cells and activated B cells from ENCODE.
These groups have enough similarities to demonstrate how this analysis looks for similar regions, but also enough changes in SE structure to be interesting.

### Call Activated B Cell Super Enhancers

We'll also want the SEs from activated B cells so that we have all the SE regions between the groups included for comparison.
This is also useful for classification of SE structure changes between groups (see below).

```{r}
actB1_url <- "https://www.encodeproject.org/files/ENCFF640GBC/@@download/ENCFF640GBC.bam"
actB1_path <- bfcrpath(bfc, actB1_url)

control_actB1_url <- "https://www.encodeproject.org/files/ENCFF391WGD/@@download/ENCFF391WGD.bam"
control_actB1_path <- bfcrpath(bfc, control_actB1_url)

peaks_actB1_url <- "https://www.encodeproject.org/files/ENCFF915WBP/@@download/ENCFF915WBP.bed.gz"
peaks_actB1_path <- bfcrpath(bfc, peaks_actB1_url)

actB1_enhancers <- run_rose(treatment = actB1_path, control = control_actB1_path, peaks = peaks_actB1_path)
```

Now we can merge the activated and naive B cell super enhancers.

```{r}
naiveB1_SEs <- naiveB1_enhancers[naiveB1_enhancers$super]
actB1_SEs <- actB1_enhancers[actB1_enhancers$super]
all_SEs <- rbind(naiveB1_SEs, actB1_SEs)

# Merge overlapping SEs between the groups
all_SEs <- reduce(all_SEs)

# Add a REGION_ID column to keep track of which bins came from which SEs for differential analysis.
mcols(all_SEs)$REGION_ID <- seq_along(all_SEs)
```


### Loading Additional Replicates

Now we need signal counts for additional replicates in each group.
Note that we could call SEs from each sample individually before merging, or use more complicated strategies to derive SEs to compare, e.g. overlap in some proportion of samples.

```{r}
naiveB2_url <- "https://www.encodeproject.org/files/ENCFF808SRS/@@download/ENCFF808SRS.bam"
naiveB2_path <- bfcrpath(bfc, naiveB2_url)

actB2_url <- "https://www.encodeproject.org/files/ENCFF267CCT/@@download/ENCFF267CCT.bam"
actB2_path <- bfcrpath(bfc, actB2_url)
```

### Differential Analysis

Now we can actually do our differential analysis.
This will compose of:

- Splitting each SE into 100 bp bins.
- Counting the signal in each bin for each replicate.
- Dropping very low signal bins.
- Run DESeq2 with pretty standard paramaeters.
- Apply LFC shrinkage.
- Merge significant bins that are within 300 bp of each other.

```{r}
library(DESeq2)
library(apeglm)

# Break into bins
se_gr_binned <- unlist(tile(all_SEs, width=100))
mcols(se_gr_binned) <- rep(mcols(all_SEs)["REGION_ID"], elementNROWS(tile(all_SEs, width=100)))

# Count reads in each bin.
se_gr_binned_counts <- regionCounts(bam.files = c(naiveB1_path, naiveB2_path, treat_path, actB2_path), 
                                    regions = se_gr_binned, 
                                    ext = 200, 
                                    param = readParam(minq = 20))

se_gr_binned_counts$group <- c(rep("naive_Bcell", 2), rep("activated_Bcell", 2))

# Drop very low count bins
smallestGroupSize <- 2
keep <- rowSums(counts(dds) >= 20) >= smallestGroupSize
dds <- dds[keep,]

dds <- DESeq(dds)
rezzy <- results(dds, contrast = c("group", "naive_Bcell", "activated_Bcell"), alpha = 0.05, lfcThreshold = log2(1.25))
res <- lfcShrink(dds, res = rezzy, coef = c("group_naive_Bcell_vs_activated_Bcell"), type = "apeglm", format = "GRanges", saveCols = "REGION_ID")
```

### Rank SEs by Number of Significant Bins Altered

To get an idea of which SEs may be affected.

```{r}
sig <- res[res$padj < 0.05 & !is.na(res$padj),]

# Get table of bins altered in each REGION_ID, ranked by count
db.ses <- as.data.frame(sig) %>% group_by(REGION_ID) %>% summarise(n = n()) %>% arrange(desc(n))

# To se_gr, add columns for number of sig bins based on matching REGION_ID
# Get db SE IDs
db.ids <- se_gr$REGION_ID %in% db.ses$REGION_ID

se_gr$NUM_ALTERED_BINS <- 0
se_gr$NUM_ALTERED_BINS[db.ids] <- db.ses$n[match(se_gr$REGION_ID[db.ids], db.ses$REGION_ID)]
```

### Merge Adjacent/Nearby Bins for Highlighting

This will get us a more interpretable set of regions to investigate.

```{r}
merged_sig <- mergeWindows(sig, tol = 300, max.width = 5000)

merged_regions <- merged_sig$regions

# Limit to those that are at least 3 bins wide
merged_regions <- merged_regions[width(merged_regions) >= 300]

# For testing, limit to those on chr6
merged_regions <- merged_regions[seqnames(merged_regions) == "chr2"]
```

### Visualization

Now we can do the usual viz, e.g. MA plots and tracks.
Depending on the groups being compared, you might expect larger shifts in the MA plot than you'd expect from a typical gene-level analysis.
SEs are relatively cell-type specific and somewhat dynamic, plus we'll be looking at the individual bins composing them.

A typical MA plot is of limited utility here, but we can still generate one.

```{r}
plotMA(rezzy, alpha = 0.05)
```

### Gviz Viz

This is a more complex example of how you might visualize the results of the differential analysis using Gviz.

```{r}
# Get region for SE with most DB bins
top.db <- db.ses$REGION_ID[66]
se.info <- se_gr[se_gr$REGION_ID == top.db,]

# Genome track
gtrack <- GenomeAxisTrack()
itrack <- IdeogramTrack(genome = "hg38")

# Annotation track
greg <- GeneRegionTrack(TxDb.Hsapiens.UCSC.hg38.knownGene, showId=TRUE,
    geneSymbol=TRUE, name="", background.title="transparent")
symbols <- unlist(mapIds(org.Hs.eg.db, gene(greg), "SYMBOL",
    "ENTREZID", multiVals = "first"))
symbol(greg) <- symbols[gene(greg)]

# SE track
setrack <- AnnotationTrack(se_gr, genome = "hg38", name = "SEs")

# SE bin data
sigfctrack <- DataTrack(range = sig, data = -sig$log2FoldChange, name = "sig_bins_FCs", genome = "hg38", 
                         ylim = c(-max(abs(sig$log2FoldChange)), max(abs(sig$log2FoldChange))), type = "b", 
                     col = "orange", background.title = "orange", baseline = 0)

# SE bin foldchanges
fctrack <- DataTrack(range = res, data = -res$log2FoldChange, name = "bin_FCs", genome = "hg38", 
                         ylim = c(-max(abs(res$log2FoldChange)), max(abs(res$log2FoldChange))), 
                     type = "b", col = "black", background.title = "black", baseline = 0)


# Signal Tracks
bw_na1 <- "./example_data/bigWigs/ENCFF993DJI.naive_Bcell.H3K27ac.rep1.bigWig"
bw_na2 <- "./example_data/bigWigs/ENCFF808SRS.naive_Bcell.H3K27ac.rep2.bigWig"
bw_act1 <- "./example_data/bigWigs/ENCFF640GBC.activated_Bcell.H3K27ac.rep1.bigWig"
bw_act2 <- "./example_data/bigWigs/ENCFF267CCT.activated_Bcell.H3K27ac.rep2.bigWig"

naive1_track <- DataTrack(range = bw_na1, type = "l", name = "naiveB_r1", genome = "hg38", 
                        col = "blue", background.title = "blue", ylim = c(0, 12), baseline = 0)
naive2_track <- DataTrack(range = bw_na2, type = "l", name = "naiveB_r2", genome = "hg38", 
                        col = "blue", background.title = "blue", ylim = c(0, 12), baseline = 0)
act1_track <- DataTrack(range = bw_act1, type = "l", name = "activatedB_r1", genome = "hg38", 
                        col = "red", background.title = "red", ylim = c(0, 12), baseline = 0)
act2_track <- DataTrack(range = bw_act2, type = "l", name = "activatedB_r2", genome = "hg38", 
                        col = "red", background.title = "red", ylim = c(0, 12), baseline = 0)

# Highlight sig bins
ht <- HighlightTrack(trackList = list(act1_track, act2_track, fctrack, sigfctrack, naive1_track, naive2_track),
                     start = start(merged_regions), end = end(merged_regions), chromosome = as.character(seqnames(se.info)),
                     fill = "#d3ff8c", col = "#8ff7df")

plotTracks(list(gtrack, itrack, greg, setrack, ht), from = start(se.info), to = end(se.info), chromosome = as.character(seqnames(se.info)), transcriptAnnotation = "symbol", collapseTranscripts = "longest")
```

## SessionInfo

<details>

<summary>Click to expand</summary>

```{r, echo = FALSE}
sessionInfo()
```

</details>
